# ğŸ•¸ï¸ Basit Web KazÄ±yÄ±cÄ± ve CSV Kaydedici (Web Scraper)

Bu proje, Python'Ä±n gÃ¼Ã§lÃ¼ kÃ¼tÃ¼phaneleri olan **`requests`** ve **`BeautifulSoup4`** kullanÄ±larak geliÅŸtirilmiÅŸ temel bir web kazÄ±ma (web scraping) aracÄ±dÄ±r. Belirlenen bir web sayfasÄ±ndan yapÄ±landÄ±rÄ±lmÄ±ÅŸ veriyi Ã§eker ve sonuÃ§larÄ± komut satÄ±rÄ±na yazdÄ±rdÄ±ktan sonra, yerleÅŸik **`csv`** modÃ¼lÃ¼ ile kalÄ±cÄ± bir `.csv` dosyasÄ±na kaydeder.

Bu proje, veri Ã§ekme, HTML ayrÄ±ÅŸtÄ±rma ve veri depolama konusundaki yetkinliÄŸimi gÃ¶sterir.

## ğŸ› ï¸ KullanÄ±lan Teknolojiler

* **Python 3.x**
* **Requests:** HTTP istekleri yapmak ve web sayfalarÄ±nÄ±n iÃ§eriÄŸini indirmek iÃ§in.
* **BeautifulSoup4 (bs4):** Ä°ndirilen HTML/XML iÃ§eriÄŸini ayrÄ±ÅŸtÄ±rmak ve veriyi seÃ§mek iÃ§in.
* **csv (YerleÅŸik ModÃ¼l):** KazÄ±nan veriyi standart bir CSV formatÄ±nda kaydetmek iÃ§in.

## ğŸš€ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

1.  **Gerekli KÃ¼tÃ¼phaneleri Kurun:**
    ```bash
    pip install requests beautifulsoup4
    ```

2.  **Betiki Ã‡alÄ±ÅŸtÄ±rÄ±n:**
    ```bash
    python web_kaziyici.py
    ```

3.  **Ã‡Ä±ktÄ±yÄ± Kontrol Edin:**
    * Komut satÄ±rÄ±nda kazÄ±nan verileri gÃ¶receksiniz.
    * Projenin bulunduÄŸu dizinde, kazÄ±nan verileri iÃ§eren `kitap_listesi.csv` dosyasÄ± oluÅŸacaktÄ±r.

## âš ï¸ Ã–nemli Not

* LÃ¼tfen kazÄ±ma (scraping) yapmadan Ã¶nce hedef web sitesinin **`robots.txt`** dosyasÄ±nÄ± ve kullanÄ±m ÅŸartlarÄ±nÄ± kontrol edin. Etik kurallara uyun.
* Ã–rnekteki `HEDEF_URL` ve HTML sÄ±nÄ±flarÄ± (`kitap-karti`, `kitap-baslik`, vb.) kurgusaldÄ±r. GerÃ§ek bir web sitesiyle deneme yaparken bu deÄŸerleri gÃ¼ncellemeyi unutmayÄ±n.

## ğŸ’¡ GeliÅŸtirme Ã–nerileri

* KullanÄ±cÄ±dan kazÄ±nacak URL'yi ve aranacak HTML sÄ±nÄ±flarÄ±nÄ± komut satÄ±rÄ±nda girmesini isteme.
* Veri Ã§ekilirken gecikme ekleyerek (rate limiting) siteye aÅŸÄ±rÄ± yÃ¼klenmeyi Ã¶nleme.
* Hata iÅŸleme mekanizmasÄ±nÄ± (Ã¶rneÄŸin, bulunamayan Ã¶ÄŸeler iÃ§in) daha da iyileÅŸtirme.
